{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OR9z9_mQhibx",
        "outputId": "195b6cb2-ff48-4159-fdb7-3996e7433cb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Model Performance on Test Set:\n",
            "MAE: 29.64\n",
            "MSE: 1717.62\n",
            "RÂ² Score: 0.6241\n",
            "\n",
            "ðŸ”§ Predicted Remaining Useful Life (RUL): 201.62 cycles\n"
          ]
        }
      ],
      "source": [
        "# aircraft_rul_model.py\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "# ========== STEP 1: LOAD AND PREPROCESS DATA ==========\n",
        "# Download the CMAPSS FD001 dataset and load it\n",
        "# https://www.nasa.gov/content/prognostics-center-of-excellence-data-set-repository\n",
        "df = pd.read_csv(\"/content/train_FD001.txt\", sep=' ', header=None)\n",
        "df.dropna(axis=1, inplace=True)\n",
        "\n",
        "# Set column names\n",
        "cols = ['unit_number', 'time_in_cycles',\n",
        "        'operational_setting_1', 'operational_setting_2', 'operational_setting_3'] + \\\n",
        "       [f'sensor_{i}' for i in range(1, 22)]\n",
        "df.columns = cols\n",
        "\n",
        "# Drop unused sensors\n",
        "drop_sensors = ['sensor_1', 'sensor_5', 'sensor_10']\n",
        "df.drop(columns=drop_sensors, inplace=True)\n",
        "\n",
        "# ========== STEP 2: COMPUTE RUL ==========\n",
        "rul_df = df.groupby('unit_number')['time_in_cycles'].max().reset_index()\n",
        "rul_df.columns = ['unit_number', 'max_cycle']\n",
        "df = df.merge(rul_df, on='unit_number', how='left')\n",
        "df['RUL'] = df['max_cycle'] - df['time_in_cycles']\n",
        "df.drop(columns='max_cycle', inplace=True)\n",
        "\n",
        "# ========== STEP 3: PREPARE FEATURES ==========\n",
        "feature_cols = [col for col in df.columns if col not in ['unit_number', 'time_in_cycles', 'RUL']]\n",
        "X = df[feature_cols]\n",
        "y = df['RUL']\n",
        "\n",
        "# ========== STEP 4: SCALING AND SPLITTING ==========\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ========== STEP 5: MODEL TRAINING ==========\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# ========== STEP 6: EVALUATION ==========\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"ðŸ“Š Model Performance on Test Set:\")\n",
        "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.2f}\")\n",
        "print(f\"MSE: {mean_squared_error(y_test, y_pred):.2f}\")\n",
        "print(f\"RÂ² Score: {r2_score(y_test, y_pred):.4f}\")\n",
        "\n",
        "# ========== STEP 7: SAVE MODEL AND SCALER ==========\n",
        "os.makedirs(\"model\", exist_ok=True)\n",
        "pickle.dump(model, open(\"model/rul_model.pkl\", \"wb\"))\n",
        "pickle.dump(scaler, open(\"model/scaler.pkl\", \"wb\"))\n",
        "pickle.dump(feature_cols, open(\"model/feature_list.pkl\", \"wb\"))\n",
        "\n",
        "# ========== STEP 8: PREDICT RUL FOR NEW ENGINE ==========\n",
        "# Example sensor input (replace these with real sensor values)\n",
        "input_data = {\n",
        "    'operational_setting_1': 0.0,\n",
        "    'operational_setting_2': 0.0,\n",
        "    'operational_setting_3': 100.0,\n",
        "    'sensor_2': 642.82,\n",
        "    'sensor_3': 1589.66,\n",
        "    'sensor_4': 1405.6,\n",
        "    'sensor_6': 21.61,\n",
        "    'sensor_7': 39.06,\n",
        "    'sensor_8': 23.28,\n",
        "    'sensor_9': 100.0,\n",
        "    'sensor_11': 39.0,\n",
        "    'sensor_12': 23.23,\n",
        "    'sensor_13': 47.47,\n",
        "    'sensor_14': 522.49,\n",
        "    'sensor_15': 2388.06,\n",
        "    'sensor_16': 8138.48,\n",
        "    'sensor_17': 8.42,\n",
        "    'sensor_18': 0.03,\n",
        "    'sensor_19': 391.0,\n",
        "    'sensor_20': 2388.0,\n",
        "    'sensor_21': 100.0\n",
        "}\n",
        "\n",
        "# Load model, scaler, and feature list\n",
        "model = pickle.load(open(\"model/rul_model.pkl\", \"rb\"))\n",
        "scaler = pickle.load(open(\"model/scaler.pkl\", \"rb\"))\n",
        "feature_list = pickle.load(open(\"model/feature_list.pkl\", \"rb\"))\n",
        "\n",
        "# Convert input into DataFrame and reorder\n",
        "X_input_df = pd.DataFrame([input_data])[feature_list]\n",
        "\n",
        "# Scale and predict\n",
        "X_scaled_input = scaler.transform(X_input_df)\n",
        "predicted_rul = model.predict(X_scaled_input)[0]\n",
        "\n",
        "print(f\"\\nðŸ”§ Predicted Remaining Useful Life (RUL): {predicted_rul:.2f} cycles\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZVl6rpR8imLM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}